defaults:
  - default

accelerator: gpu
devices: auto

precision: 'bf16-mixed' # 'bf16-true' # 'transformer-engine', 'transformer-engine-float16', '16-true', '16-mixed', 'bf16-true',
# 'bf16-mixed', '32-true',

# DeepSpeedStrategy
strategy:
   _target_: lightning.pytorch.strategies.DeepSpeedStrategy
  # ZeRO optimization
   zero_optimization: True
   stage: 2
   offload_optimizer: False
   offload_optimizer_device: "cpu"  # only relevant if offload_optimizer=True
   contiguous_gradients: True

  # Activation Checkpointing
   partition_activations: False
   cpu_checkpointing: False

# Gradient accumulation
accumulate_grad_batches: 1

# Clip gradients by the global norm
gradient_clip_val: 10.0

# frequency of logging
log_every_n_steps: 20

# How often to check the validation set. float in the range [0.0, 1.0] to check after a fraction of the training epoch.
val_check_interval: 0.25  # checks 4 times every epoch

limit_train_batches: 1.0  # use the entire training set
limit_val_batches: 0.0  # no validation